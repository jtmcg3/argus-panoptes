# Argus-Panoptes Docker Compose
# Production deployment with OpenAI/ChatGPT integration

services:
  # API Gateway (primary entry point)
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: panoptes-api
    command: ["panoptes-api", "--port", "8080", "--config", "/app/config/default.toml"]
    environment:
      - RUST_LOG=info,panoptes=debug,tower_http=debug
      - OPENAI_API_KEY=${OPENAI_API_KEY:?OPENAI_API_KEY is required}
      - PANOPTES_API_KEY=${PANOPTES_API_KEY}
      - PANOPTES_BIND_ADDR=0.0.0.0
      - PANOPTES_CORS_ORIGINS=${PANOPTES_CORS_ORIGINS}
    volumes:
      - ../config:/app/config:ro
      - panoptes-data:/app/data
    ports:
      - "8080:8080"
    networks:
      - panoptes-net
    restart: unless-stopped
    # SEC-014: Security hardening
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
      - /run:noexec,nosuid,size=10m
    cap_drop:
      - ALL
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # PTY-MCP server (for Claude CLI execution)
  pty-mcp:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: panoptes-pty-mcp
    command: ["pty-mcp-server"]
    environment:
      - RUST_LOG=info,panoptes_pty_mcp=debug
    volumes:
      - workspaces:/workspaces
    networks:
      - panoptes-net
    restart: unless-stopped
    # SEC-014: Security hardening
    # Removed: privileged: true (was unnecessary)
    # Removed: /var/run/docker.sock mount (attack surface)
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
      - /run:noexec,nosuid,size=10m
    cap_drop:
      - ALL
    cap_add:
      - SYS_PTRACE  # Required for PTY terminal emulation

  # Optional: Ollama for local LLM inference (fallback when OpenAI unavailable)
  # Uncomment if you want local LLM support
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: panoptes-ollama
  #   profiles:
  #     - local-llm
  #   volumes:
  #     - ollama-models:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - panoptes-net
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]

volumes:
  panoptes-data:
    driver: local
  workspaces:
    driver: local
  # ollama-models:
  #   driver: local

networks:
  panoptes-net:
    driver: bridge
